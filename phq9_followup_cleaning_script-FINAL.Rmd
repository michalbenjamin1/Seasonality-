---
title: "PHQ9 Follow Up Cleaning Script"
author: "Michal Benjamin"
date: "08/02/2024"
output: html_document
---

## Standards
All arguments should be in their own row, including the first argument
Closing bracket should have its own row
Functions with a single argument can have this on the same line
One argument can be hashed out per line for debugging errors

Chunk names should be all lower case except:
Study name (e.g. GLAD/EDGI/NBR) all caps
Capitalised first word
Chunk names MUST be unique

Add only one empty line between chunks
Add one extra line when starting a new section
Use hash syntax as appropriate for headings and subheadings, as per markdown syntax

Points requiring user input are enclosed thus <>

Ensure that you have deleted/untracked .DS_Store before your initial commit
Ensure that your  .gitignore contains "**/.DS_Store" before your initial commit

Configure global options for all chunks
```{r Setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  comment = '',
  prompt = FALSE,
  cache = FALSE
  )
```

Clear global environment prior to initiation
```{r Clear global environment}
remove(list = ls())
```


```{r Read in file with path to ilovedata channel on teams}
source(file = "scripts/credentials/paths.R")
```

Add the add_labelled_numeric function - used to convert character variables into numeric variables
Add the remove_duplicates function - used to deduplicate and remove NAs from IDs
Add the sumscores function - used to generate sumscores
Add the package_check function - used to install and load dependencies
Add the recode_check function - used to check for implausible values when recoding
Add the imp_clean function - used to check variables for implausible values
Add the cont_clean function - used to check continuous variables for implausible values
```{r Read in functions}
source(file = "scripts/functions/add_labelled_numeric.R")
source(file = "scripts/functions/remove_duplicates.R")
source(file = "scripts/functions/sumscores.R")
source(file = "scripts/functions/package_check.R")
source(file = "scripts/functions/recode_check.R")
source(file = "scripts/functions/cont_clean.R")
source(file = "scripts/functions/replace_name.R")
```

Use package_check to install and load dependencies
Load tidyverse last
```{r Install load dependencies}
packages <- c("sjlabelled",
              "Amelia",
              "gtsummary",
              "tidyverse")

package_check(packages)
```


# Read in the data: PHQ 9 follow up data 
Change this heading to the name of your questionnaire/demographic
Load GLAD data first, then EDGI, then NBR, then RAMP

Do not change variable names from the NLP names that are produced by the extraction
EXCEPT in exceptional circumstances
Document ANY changes to variable names in the issues spreadsheet "https://docs.google.com/spreadsheets/d/1a2gL8c0eH2pZXNTbnPzkDYQGeeVXbLKU8BUpYM0moe8/edit?usp=sharing"

- For created variable names, use ONLY 'questionnaire.variable_name'
- For dataset, only use snake_case naming
- When using pipe operator '%>%', each function should begin on a new line
- Do not add empty lines at the beginning or end of a chunk
- Use only tidyverse functions wherever possible
- When naming chunks, begin with the name of the dataset (GLAD, EDGI, NBR, RAMP) where appropriate



## phq_coping_followupa.rds
```{r phq9 coping follow up a read in data}
phq_cop_fua_dat <- read_rds("/project/seasonal_internalising_2024/phq_coping_followupa.rds")
  
# Check variable names in dataframe
phq_cop_fua_dat %>%
  colnames()

# Inspect dimensions of dataframe 
phq_cop_fua_dat %>%
  dim()
```

Specify columns to be excluded from add_numeric function
Continuous variables should be excluded, as they are already numeric
```{r exclude continuous variables}
exclude_cols_numeric <- c(
  "ID",
  "sample",
  "startDate",
  "endDate"
  )
```

Select & rename relevant columns (will be a function at some point)
```{r phq9 coping follow up a select}
phq_cop_fua_dat_id <- phq_cop_fua_dat %>% #new dataset with ID
  drop_na(externalDataReference) %>% # Drop participants with no ID
  #remove_duplicates("externalDataReference") %>% # Remove duplicate IDs
  add_column(sample = "phq9_fua",
             .after = "externalDataReference") %>% # Create new sample column
  select(
         ID = externalDataReference,# ID
         sample,
         startDate,
         endDate,
         phq9.little_interest_or_pleasure_in_doing_things_cop = phq9.little_interest_or_pleasure_in_doing_things,
         phq9.feeling_down_depressed_or_hopeless_cop = phq9.feeling_down_depressed_or_hopeless,
         phq9.staying_asleep_sleeping_trouble_cop = phq9.sleeping_trouble_falling_asleep,
         phq9.feeling_tired_or_having_little_energy_cop = phq9.feeling_tired_or_having_little_energy,
         phq9.poor_appetite_or_overeating_cop = phq9.poor_appetite_or_overeating,
         phq9.feeling_bad_failure_family_cop = phq9.failure_feeling_bad_family,
         phq9.trouble_concentrating_reading_newspaper_cop = phq9.newspaper_reading_things_trouble,
         phq9.slowly_speaking_moving_noticed_cop = phq9.slowly_speaking_moving_noticed,
         phq9.moving_fidgety_noticed_opposite_cop = phq9.fidgety_opposite_moving_restless,
         phq9.dead_hurting_thoughts_cop = phq9.dead_hurting_thoughts, 
         phq9.difficult_daily_life_issues_cop = phq9.difficult_daily_life_issues
         )
  # %>%
  #   add_labelled_numeric(exclude = exclude_cols_numeric, leaders = exclude_cols_numeric)

colslogic<-!(colnames(phq_cop_fua_dat_id) %in% exclude_cols_numeric)
colnames(phq_cop_fua_dat_id)[colslogic]<-paste0(colnames(phq_cop_fua_dat_id)[colslogic],"_numeric")
  
# Inspect colnames
phq_cop_fua_dat_id %>%
  colnames()

```

Look at number of people excluded
```{r phq9 coping follow up a number excluded}
# Inspect dimensions of new data set
phq_cop_fua_dat_id %>%
  dim()


# Inspect number of rows dropped
phq_cop_fua_excluded <- dim(phq_cop_fua_dat_id)[1] - dim(phq_cop_fua_dat)[1]
phq_cop_fua_excluded
```

Inspect numeric variables
```{r phq9 coping follow up a inspect numeric variables}
phq_cop_fua_dat_id %>%
  select(all_of(ends_with("numeric"))) %>%
  tbl_summary(missing_text = "Missing")
```

Check missingness by missmap
```{r phq9 coping follow up a inspect missingness}
phq_copa_fua_miss_map <- phq_cop_fua_dat_id %>% 
  missmap()
phq_copa_fua_miss_map
```

## phq_coping_followupb.rds
```{r phq9 coping follow up b read in data}
phq_cop_fub_dat <- read_rds("/users/k21043154/project/seasonal_internalising_2024/data/phenotypic/raw_data_old/phq_coping_followupb.rds")
  
# Check variable names in dataframe
phq_cop_fub_dat %>%
  colnames()

# Inspect dimensions of dataframe 
phq_cop_fub_dat %>%
  dim()
```

Specify columns to be excluded from add_numeric function
Continuous variables should be excluded, as they are already numeric
```{r exclude continuous variables}
exclude_cols_numeric <- c(
  "ID",
  "sample",
  "startDate",
  "endDate"
  )
```

Select & rename relevant columns (will be a function at some point)
```{r phq9 coping follow up b select}
phq_cop_fub_dat_id <- phq_cop_fub_dat %>% #new dataset with ID
  drop_na(externalDataReference) %>% # Drop participants with no ID
  #remove_duplicates("externalDataReference") %>% # Remove duplicate IDs
  add_column(sample = "phq9_fub",
             .after = "externalDataReference") %>% # Create new sample column
   select(
         ID = externalDataReference,# ID
         sample,
         startDate,
         endDate,
         phq9.little_interest_or_pleasure_in_doing_things_cop = phq9.little_interest_or_pleasure_in_doing_things,
         phq9.feeling_down_depressed_or_hopeless_cop = phq9.feeling_down_depressed_or_hopeless,
         phq9.staying_asleep_sleeping_trouble_cop = phq9.sleeping_trouble_falling_asleep,
         phq9.feeling_tired_or_having_little_energy_cop = phq9.feeling_tired_or_having_little_energy,
         phq9.poor_appetite_or_overeating_cop = phq9.poor_appetite_or_overeating,
         phq9.feeling_bad_failure_family_cop = phq9.failure_family_feeling_bad,
         phq9.trouble_concentrating_reading_newspaper_cop = phq9.trouble_concentrating_newspaper_reading,
         phq9.slowly_speaking_moving_noticed_cop = phq9.slowly_noticed_speaking_moving,
         phq9.moving_fidgety_noticed_opposite_cop = phq9.fidgety_opposite_moving_restless,
         phq9.dead_hurting_thoughts_cop = phq9.dead_hurting_thoughts, 
         phq9.difficult_daily_life_issues_cop = phq9.difficult_daily_life_issues
         )
# %>%
#   add_labelled_numeric(exclude = exclude_cols_numeric, leaders = exclude_cols_numeric)

colslogic<-!(colnames(phq_cop_fub_dat_id) %in% exclude_cols_numeric)
colnames(phq_cop_fub_dat_id)[colslogic]<-paste0(colnames(phq_cop_fub_dat_id)[colslogic],"_numeric")
  
# Inspect colnames
phq_cop_fub_dat_id %>%
  colnames()
```

Look at number of people excluded
```{r phq9 coping follow up b number excluded}
# Inspect dimensions of new data set
phq_cop_fub_dat_id %>%
  dim()


# Inspect number of rows dropped
phq_cop_fub_excluded <- dim(phq_cop_fub_dat_id)[1] - dim(phq_cop_fub_dat)[1]
phq_cop_fub_excluded
```

Inspect numeric variables
```{r phq9 coping follow up b inspect numeric variables}
phq_cop_fub_dat_id %>%
  select(all_of(ends_with("numeric"))) %>%
  tbl_summary(missing_text = "Missing")
```

Check missingness by missmap
```{r phq9 coping follow up b inspect missingness}
phq_cop_fub_miss_map <- phq_cop_fub_dat_id %>% 
  missmap()
phq_cop_fub_miss_map
```

## phq_coping_followupa_ongoing.rds
```{r phq9 coping follow up a ongoing read in data}
phq_cop_fua_o_dat <- read_rds("/users/k21043154/project/seasonal_internalising_2024/data/phenotypic/raw_data_old/phq_coping_followupa_ongoing.rds")
  
# Check variable names in dataframe
phq_cop_fua_o_dat %>%
  colnames()

# Inspect dimensions of dataframe 
phq_cop_fua_o_dat %>%
  dim()
```

Specify columns to be excluded from add_numeric function
Continuous variables should be excluded, as they are already numeric
```{r exclude continuous variables}
exclude_cols_numeric <- c(
  "ID",
  "sample",
  "startDate",
  "endDate"
  )
```

Select & rename relevant columns (will be a function at some point)
```{r phq9 coping follow up a ongoing select}
phq_cop_fua_o_dat_id <- phq_cop_fua_o_dat %>% #new dataset with ID
  drop_na(externalDataReference) %>% # Drop participants with no ID
  #remove_duplicates("externalDataReference") %>% # Remove duplicate IDs
  add_column(sample = "phq9_fua_o",
             .after = "externalDataReference") %>% # Create new sample column
  select(
         ID = externalDataReference,# ID
         sample,
         startDate,
         endDate,
         phq9.little_interest_or_pleasure_in_doing_things_cop = phq9.little_interest_or_pleasure_in_doing_things,
         phq9.feeling_down_depressed_or_hopeless_cop = phq9.feeling_down_depressed_or_hopeless,
         phq9.staying_asleep_sleeping_trouble_cop = phq9.sleeping_trouble_falling_asleep,
         phq9.feeling_tired_or_having_little_energy_cop = phq9.feeling_tired_or_having_little_energy,
         phq9.poor_appetite_or_overeating_cop = phq9.poor_appetite_or_overeating,
         phq9.feeling_bad_failure_family_cop = phq9.failure_feeling_bad_family,
         phq9.trouble_concentrating_reading_newspaper_cop = phq9.newspaper_reading_things_trouble,
         phq9.slowly_speaking_moving_noticed_cop = phq9.slowly_speaking_moving_noticed,
         phq9.moving_fidgety_noticed_opposite_cop = phq9.fidgety_opposite_moving_restless,
         phq9.dead_hurting_thoughts_cop = phq9.dead_hurting_thoughts, 
         phq9.difficult_daily_life_issues_cop = phq9.difficult_daily_life_issues
         )
  # %>%
  # add_labelled_numeric(exclude = exclude_cols_numeric, leaders = exclude_cols_numeric)
#+++JZ: fix to numeric columns to follow the old standard of gad7 cleaning
colslogic<-!(colnames(phq_cop_fua_o_dat_id) %in% exclude_cols_numeric)
colnames(phq_cop_fua_o_dat_id)[colslogic]<-paste0(colnames(phq_cop_fua_o_dat_id)[colslogic],"_numeric")
  
# Inspect colnames
phq_cop_fua_o_dat_id %>%
  colnames()
```

Look at number of people excluded
```{r phq9 coping follow up a ongoing number excluded}
# Inspect dimensions of new data set
phq_cop_fua_o_dat_id %>%
  dim()


# Inspect number of rows dropped
phq_cop_fua_o_excluded <- dim(phq_cop_fua_o_dat_id)[1] - dim(phq_cop_fua_o_dat)[1]
phq_cop_fua_o_excluded
```

Inspect numeric variables
```{r phq9 coping follow up a ongoing inspect numeric variables}
phq_cop_fua_o_dat_id %>%
  select(all_of(ends_with("numeric"))) %>%
  tbl_summary(missing_text = "Missing")
```

Check missingness by missmap
```{r phq9 coping follow up a ongoing inspect missingness}
phq_cop_fua_o_miss_map <- phq_cop_fua_o_dat_id %>% 
  missmap()
phq_cop_fua_o_miss_map
```


# Combining Data

Bind rows of FOllow up A, B and A ongoing
Read in data, bind datasets, then clean all together
```{r Merge data sets}
nrow(phq_cop_fua_dat_id)
nrow(phq_cop_fub_dat_id)
nrow(phq_cop_fua_o_dat_id)
dat <- bind_rows(phq_cop_fua_dat_id,phq_cop_fub_dat_id, phq_cop_fua_o_dat_id)

nrow(dat)

# Check dat using glimpse before continuing
dat %>% glimpse()
```

Extract and save labels
```{r Extract save labels}
# Save variable labels
question_labels <- sjlabelled::get_label(dat)

# Save value labels
answer_labels <- sjlabelled::get_labels(dat, values = "as.name")

# Change -77 to -777 in value labels names
chng <- rapply(sapply(answer_labels, names),
               function(x) ifelse(x==-77, -777, x),
               how = "replace")

# Add multiple lines here as necessary to change other nonanswer values in labels
chng <- rapply(chng,
                function(x) ifelse(x==-88, -888, x),
                how = "replace")
chng <- rapply(chng,
                function(x) ifelse(x==-11, -111, x),
                how = "replace")
chng <- rapply(chng,
                function(x) ifelse(x==-22, -222, x),
                how = "replace")
chng <- rapply(chng,
                function(x) ifelse(x==-33, -333, x),
                how = "replace")
chng <- rapply(chng,
                function(x) ifelse(x==-44, -444, x),
                how = "replace")
chng <- rapply(chng,
                function(x) ifelse(x==-55, -555, x),
                how = "replace")
chng <- rapply(chng,
                function(x) ifelse(x==-66, -666, x),
                how = "replace")
chng <- rapply(chng,
                function(x) ifelse(x==-99, -999, x),
                how = "replace")


# Substitute new value labels into answer_labels
for (i in 1:length(chng)){
  if(!is.null(answer_labels[[i]])){
    names(answer_labels[[i]]) <- chng[[i]]
  }
}
```

Recode Non-answer values to 3 digits
-555 'Not applicable' response from participant
-777 Seen but not answered
-888 Don't know
-999 Prefer not to answer/Prefer not to say
`NA` Were not shown the question (genuinely missing value)
When we code someone as being 'not applicable' by deduction, we use `NA_real_`
```{r Recode NA values}
dat <- dat %>%
  mutate(across(where(is.numeric),
                ~case_when(
                  . == -55 ~ -555,
                  . == -77 ~ -777,
                  . == -88 ~ -888,
                  . == -99 ~ -999,
                  TRUE ~ .)
                )
         )

# Re-add labels after mutate
dat <- sjlabelled::set_label(dat, question_labels)
dat <- sjlabelled::set_labels(dat, labels = answer_labels)
```

Create list of all labels and attributes
This chunk supersedes all categorical/numeric cleaning
It gives you an output of c(the question label, all value-label pairs)
for each variable
Check for errors in the output of this chunk, including:
- Label spelling errors (for questions and answers)
- Incorrect values
- Mismatches between labels and values
- Scale errors
- Variable naming issues from the data extraction
- Any other issues you can see
All issues/changes need to be logged as a to-do on Teams with yourself and Saakshi/Mika tagged
At this point, you also need to pick out any continuous, date or text variables 
to be cleaned in the later chunks
```{r List labels attrs}
label_list <- sapply(dat, function(x) c(attr(x, "label"), attr(x, "labels")))
label_list
```


# Cleaning Continuous Variables

Create vector of continuous variables
(I suggest adding variable names sorted by type e.g. all ages then all years
etc. to make your life easier when creating limits_mat)
```{r Create cont vars vector}
variables_cont <- c(
         "phq9.little_interest_or_pleasure_in_doing_things_cop_numeric",
         "phq9.feeling_down_depressed_or_hopeless_cop_numeric",
         "phq9.staying_asleep_sleeping_trouble_cop_numeric",
         "phq9.feeling_tired_or_having_little_energy_cop_numeric",
         "phq9.poor_appetite_or_overeating_cop_numeric",
         "phq9.feeling_bad_failure_family_cop_numeric",
         "phq9.trouble_concentrating_reading_newspaper_cop_numeric",
         "phq9.slowly_speaking_moving_noticed_cop_numeric",
         "phq9.moving_fidgety_noticed_opposite_cop_numeric",
         "phq9.dead_hurting_thoughts_cop_numeric", 
         "phq9.difficult_daily_life_issues_cop_numeric"
              )

# Check length of vector (must match dim(limits_mat)[1])
length(variables_cont)
```

Inspect continuous variables
Use the question labels to ascertain context at this point and check for obvious outliers
The percentiles can be modified to exclude nonanswer values as appropriate to your data
```{r Initial inspect cont vars}
#dat %>%
  #select(all_of(variables_cont)) %>%
  #tbl_summary(
    #missing_text = "Missing",
    #statistic = list(all_continuous() ~ "{median} ({p0}, {p5}, {p95}, {p100})"))
```

Check for text in continuous variables
This chunk outputs only the columns and rows that contain text
```{r Cont vars check text}
# Function to check for any text or spaces
check_for_string <- function(x){
  sum(str_detect(x, "[a-zA-Z\\s]+"), na.rm = TRUE) > 0}

dat %>%
  # select all continuous
  select(all_of(variables_cont)) %>%
  # select only vars containing text
  select(where(check_for_string)) %>%
  # filter only rows containing text
  filter(
    if_any(where(check_for_string),
           ~str_detect(., "[a-zA-Z\\s]+")
           )
    )
```



Remove text from numeric variables automatically
ONLY use this chunk if there is NO INFORMATION to be gained from the text
```{r Cont vars remove text}
dat <- dat %>%
  mutate(across(all_of(variables_cont),
                ~str_remove(., "[a-zA-Z\\s]+")
                )
         )
```

Remove empty variables from variables_cont
These all contain only NAs and serve only to interfere with processing
```{r Cont vars remove empty}
variables_empty <- dat %>%
  select(all_of(variables_cont)) %>%
  select(where(~all(is.na(.))
               )
         ) %>%
  colnames()

variables_cont <- variables_cont[!variables_cont %in% variables_empty]
length(variables_cont)
```

Mutate variables to numeric after cleaning out text
This step is necessary to check for non-integer values
If you have correctly cleaned them above, this chunk should not have any failures to parse
```{r Cont vars to numeric}
dat <- dat %>%
  mutate(across(all_of(variables_cont),
                ~as.numeric(.)
                )
         )
```

Transform nonanswer values to 3 digit
```{r Cont vars nonanswer}
dat <- dat %>%
  mutate(across(where(is.numeric),
                ~case_when(
                  . == -55 ~ -555,
                  . == -77 ~ -777,
                  . == -88 ~ -888,
                  . == -99 ~ -999,
                  TRUE ~ .)
                )
         )

# Re-add labels after mutate
dat <- sjlabelled::set_label(dat, question_labels)
dat <- sjlabelled::set_labels(dat, labels = answer_labels)
```

Create matrix of limits for continuous variables
Matrix is series of vectors (lower, upper)
Define limits for variable and list reasoning below
<Variable type 1>: <any explanation required>
- Lower: <limit> <justification>
- Upper: <limit> <justification>

<Variable type 2>: <any explanation required>
- Lower: <limit> <justification>
- Upper: <limit> <justification>
```{r Create matrix limits}
# Create a vector of limits for each type of variable using rep
# Create a vector of limits for each type of variable using rep
limits_numeric <- rep(c(0, 3), 33) 


# Combine the vectors together
#limits_vec <- c(limits_<variable type 1>,
                #limits_<variable type 2>
                # add more as necessary
                #)

# Create matrix, matrices are filled by columns, not rows, so must transpose
limits_mat <- t(matrix(limits_numeric, # take values from your vector of limits
                       nrow = 2, # upper and lower bounds
                       ncol = length(variables_cont) # number of variables total
                       )
                )

# Check dimensions
dim(limits_mat)
```

Set row and col names of limits_mat
This allows your to easily refer back to limits_mat for a summary
```{r Set lim_mat names}
rownames(limits_mat) <- variables_cont
colnames(limits_mat) <- c("Lower", "Upper")
```

Use cont_clean to check if any implausible values and provide replacement vectors
Cont_clean will not proceed if variables are not numeric type, clean manually above if necessary
This chunk reports any variables that contain implausible values
```{r Cont_clean cont vars}
# Execute cleaning function
cont_list <- cont_clean(
  variables = variables_cont,
  limits_mat = limits_mat,
  dat = dat
)

# Create empty list of variable names to check
implaus_checklist <- c()

# Loop through function output
for (i in 1:length(variables_cont)){
  
  # Report only variables containing implausibles
  if(cont_list[[variables_cont[i]]]$Count > 0){
    
    # Add variable name to imp_checklist
    implaus_checklist <- append(x = implaus_checklist, variables_cont[i])
    
    # Report readout of implausible values
    print(paste0("Implausibles in ", variables_cont[i], ": ", cont_list[[variables_cont[i]]]$Count))
  }
}
```

Check unique values in variables containing implausible values
The sort() function allows you to see them more clearly

Check for any systematic errors at this stage
e.g. For 'age', participants may have entered a calendar year (e.g. 2001), instead of an age (e.g. 45)
It may be possible to gain data from errors like this, so DO NOT MUTATE TO IMPLAUSIBLE WITHOUT GOOD REASON
If you are unsure, RAISE IN THURSDAY DATA CLEANING MEETING
(You could import participant birth year and subtract to find age, for example)
```{r Cont vars implausible unique}
dat %>%
  select(all_of(implaus_checklist)) %>%
  sapply(., function(x) sort(unique(x)))
```



Re-inspect variables after cleaning
```{r Cont vars inspect after cleaning}
dat %>%
  select(all_of(variables_cont)) %>%
  tbl_summary(
    missing_text = "Missing",
    statistic = list(all_continuous() ~ "{median} ({p0}, {p5}, {p95}, {p100})")
  )
```

# Cleaning Dates

Create vector of date variables
```{r Vector date vars}
variables_date <- c(
  "startDate",
  "endDate"
)
```

Check for text in date variables
This chunk outputs only the columns and rows that contain text
```{r Date vars check text}
# Function to check for any text or spaces
check_for_string <- function(x){
  sum(str_detect(x, "[a-zA-Z\\s]+"), na.rm = TRUE) > 0}

dat %>%
  # select all continuous
  select(all_of(variables_date)) %>%
  # select only vars containing text
  select(where(check_for_string)) %>%
  # filter only rows containing text
  filter(
    if_any(where(check_for_string),
           ~str_detect(., "[a-zA-Z\\s]+")
           )
    )
```

Manually clean date variables if necessary
IF the text data contains useful info that can be converted to date, clean manually
For example, "Feb 2020" can be converted to "01/02/2020", avoiding unnecessary data loss


Remove text from numeric variables automatically
ONLY use this chunk if there is no further information to be gained from the text by manual cleaning
```{r Date vars remove text}
# dat <- dat %>%
#   mutate(across(all_of(variables_date),
#                 ~str_remove(., "[a-zA-Z\\s]+")
#                 )
#          )
```

Replace -77 values with NA: POSIX will reject -77 as a value when converting
```{r Date vars recode -77 to NA}
dat <- dat %>% 
  mutate(across(all_of(variables_date),
                ~as.character(.)
                )
         ) %>%
  mutate(across(all_of(variables_date),
                ~na_if(., "-77")
                )
         )
```

Parse dates using lubridate
If you have worked correctly above, there should be no failures to parse
```{r Parse date vars}
dat <- dat %>% 
  mutate(across(all_of(variables_date),
                ~lubridate::parse_date_time(x = .,
                                            orders = c("ymdHMS" , "ymd" , "d m y", "d/m/y", "d.m.y"),
                                            tz = "Europe/London")
                )
         )
```

Recheck date variables
```{r Recheck parsed date vars}
dat %>%
  select(all_of(variables_date)) %>%
  tbl_summary(missing_text = "Missing")
```

Define limits for variable and list reasoning below
Variable name:
- Upper: 
- Lower: 
```#{r Date vars define limits}
#upper_limit <- as.POSIXct("yyyy-mm-dd")
#lower_limit <- as.POSIXct("yyyy-mm-dd")
```

Recode variable outliers to NA
```{r Date vars recode outliers to NA}
#dat <- dat %>%
    #mutate(across(all_of(variables_date),
                  #~ifelse(. > upper_limit | # bigger than the upper limit
                          #. < lower_limit, # smaller than the lower limit
                          #yes = NA_real_,
                          #no = .)
      #            )
       #    ) %>%
  #mutate(across(all_of(variables_date),
                #~as.POSIXct(.,
                            #origin = lubridate::origin)
        #        )
        # )
```

Re-check dates
```{r Recheck cleaned date vars}
# dat %>%
#   select(all_of(variables_date)) %>%
#   tbl_summary(missing_text = "Missing")
```


# Produce sumscores

Reference the scoring guidance that you have used for your questionnaire here <"link">

If changing na_limit, CHECK your guidance, na_limit > 0 will replace NAs with 0, ensure that this is correct for your scoring guidance before proceeding

The coding_keys vector must contain 1s for all variables to be added and -1 for all variables to be subtracted.
 - Putting 0 in the vector will omit the variable at that position.
 - length(coding_keys) MUST be the same as the number of variables to be summed

sum_vars vector should contain ONLY and ALL variable names needed for scoring, do not add "ID" or "sample" etc.

If using reverse keying:
 - MAKE SURE that reverse = TRUE is included as an argument, reverse keying will not work without this
 - reverse_vars should contain all variable names to be reverse keyed
 - If running multiple sumscores requiring reverse keying, a single reverse_vars vector containing all of the variable names to be reverse keyed is sufficient: `%in%` will pick the relevant variables for each sumscore

These warnings are normal:
 - "Scores vector contains missing values."
 - "Input contains non-answer values. These will be converted to NA_real_ for this calculation."

They are there to inform you that some sumscores have not been calculated due to non-answer values (e.g. -777) being present.
Any other errors or warnings need to be investigated.

Create required variables for sumscore arguments
```{r Sumscores inputs}
keys <- c(
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1
  )
  # should be a vector of 1s, 0s or -1s
  

sum_vars <- c(
        "phq9.little_interest_or_pleasure_in_doing_things_cop_numeric",
         "phq9.feeling_down_depressed_or_hopeless_cop_numeric",
         "phq9.staying_asleep_sleeping_trouble_cop_numeric",
         "phq9.feeling_tired_or_having_little_energy_cop_numeric",
         "phq9.poor_appetite_or_overeating_cop_numeric",
         "phq9.feeling_bad_failure_family_cop_numeric",
         "phq9.trouble_concentrating_reading_newspaper_cop_numeric",
         #"phq9.slowly_speaking_moving_noticed_cop_numeric", #Not included in PHQ9 scoring system
         "phq9.moving_fidgety_noticed_opposite_cop_numeric",
         "phq9.dead_hurting_thoughts_cop_numeric"
         #"phq9.difficult_daily_life_issues_cop_numeric" #Not included in PHQ9 scoring system
)


```

Generate sumscores from questionnaire data and use mutate onto dat as new column
sumscores assumes that all items in the questionnaire have the SAME minimum and maximum scores for ALL items, ensure that this is correct before proceeding

When adding the column name for your sumscore use "questionnaire.score_name"

Sumscores will produce a list of 2 elements, the first is "scores", the second is "na.count"

Add "scores" to your dataframe only, "na.count" provides a report of the number of NAs in the scoring variables for each participant

Generate sumscores
```{r Generate sumscores}
library(skimr)
sum_out <- sumscores(input = dat,
                     sum_vars = sum_vars,
                     # reverse = TRUE,
                     # reverse_vars = reverse_vars,
                     coding_keys = keys,
                     na_allowed = 0,
                     min_item =0 ,
                     max_item =3 ,
                     min_score =0 ,
                     max_score =27 
                     )
skim(sum_out)
```

Add sumscores as new column
```{r Add sumscores}
dat <- dat %>%
  mutate(
    phq9.sum_score_cop = sum_out$scores
  )

```


# Create phenotypes- Not doing this step currently, maybe useful for further research
## Current depression
Create binary phenotypes based on PHQ9 scoring criteria
Validity has been assessed against an independent structured mental health professional (MHP) interview. PHQ-9 score ≥10 had a sensitivity of 88% and a specificity of 88% for major depression. 

#  Saving data
##All data
```{r Write cleaned  variables to a .rds file}
dat %>% 
  saveRDS(
    file = file.path(("/users/k21043154/project/seasonal_internalising_2024/data/phenotypic/raw_data_old/phq_coping_followupall_clean.rds")
    )
```

## Follow up A
```{r Write cleaned follow up a variables to a .rds file}
dat %>% 
  filter(sample == "phq9_fua") %>%  # select only follow up A data
  saveRDS(
    file = file.path(ilovedata,"data","latest_freeze","coping_glad_edgi_nbr","clinical", "phq9_followup_a_clean.rds")
    )
```

## Follow up B
```{r Write cleaned follow up a variables to a .rds file}
dat %>% 
  filter(sample == "phq9_fub") %>%  # select only follow up B data
  saveRDS(
    file = file.path(ilovedata,"data","latest_freeze","coping_glad_edgi_nbr","clinical", "phq9_followup_b_clean.rds")
    )
```

## Follow up A ongoing
```{r Write cleaned follow up a variables to a .rds file}
dat %>% 
  filter(sample == "phq9_fua_o") %>%  # select only follow up B data
  saveRDS(
    file = file.path(ilovedata,"data","latest_freeze","coping_glad_edgi_nbr","clinical", "phq9_followup_a_ongoing_clean.rds")
    )
```

